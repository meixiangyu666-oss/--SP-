import streamlit as st
import pandas as pd
from collections import defaultdict
import re
import uuid
import os

# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(page_title="SP-æ‰¹é‡æ¨¡ç‰ˆç”Ÿæˆå·¥å…·", page_icon="ğŸ“Š", layout="centered")

# è‡ªå®šä¹‰ CSS æ ·å¼
st.markdown("""
    <style>
    /* ä¸»æ ‡é¢˜æ ·å¼ */
    .main-title {
        font-size: 2.5em;
        font-weight: bold;
        color: #2C3E50;
        text-align: center;
        margin-bottom: 20px;
    }
    /* æç¤ºæ–‡å­—æ ·å¼ */
    .instruction {
        font-size: 1.1em;
        color: #34495E;
        margin-bottom: 20px;
    }
    /* æŒ‰é’®æ ·å¼ */
    .stButton>button {
        background-color: #3498DB;
        color: white;
        border-radius: 8px;
        padding: 10px 20px;
        font-size: 1em;
        font-weight: bold;
    }
    .stButton>button:hover {
        background-color: #2980B9;
    }
    /* ä¸‹æ‹‰èœå•æ ·å¼ */
    .stSelectbox label {
        font-size: 1.1em;
        color: #2C3E50;
        font-weight: bold;
    }
    /* æ–‡ä»¶ä¸Šä¼ æ¡†æ ·å¼ */
    .stFileUploader label {
        font-size: 1.1em;
        color: #2C3E50;
        font-weight: bold;
    }
    /* æˆåŠŸå’Œé”™è¯¯æ¶ˆæ¯æ ·å¼ */
    .stSuccess {
        background-color: #E8F5E9;
        border-left: 5px solid #4CAF50;
        padding: 10px;
        border-radius: 5px;
    }
    .stError {
        background-color: #FFEBEE;
        border-left: 5px solid #F44336;
        padding: 10px;
        border-radius: 5px;
    }
    .stWarning {
        background-color: #FFF3E0;
        border-left: 5px solid #FF9800;
        padding: 10px;
        border-radius: 5px;
    }
    </style>
""", unsafe_allow_html=True)

# é€šç”¨å‡½æ•°ï¼šä»è°ƒç ” Excel ç”Ÿæˆè¡¨å¤´ Excel
def generate_header_from_survey(uploaded_file, output_file, country, sheet_name=0):
    try:
        # è¯»å–ä¸Šä¼ çš„ Excel æ–‡ä»¶
        df_survey = pd.read_excel(uploaded_file, sheet_name=sheet_name)
        st.write(f"æˆåŠŸè¯»å–æ–‡ä»¶ï¼Œæ•°æ®å½¢çŠ¶ï¼š{df_survey.shape}")
        st.write(f"åˆ—ååˆ—è¡¨: {list(df_survey.columns)}")
    except FileNotFoundError:
        st.error(f"é”™è¯¯ï¼šæ— æ³•è¯»å–ä¸Šä¼ çš„æ–‡ä»¶ã€‚è¯·ç¡®ä¿æ–‡ä»¶æ ¼å¼æ­£ç¡®ã€‚")
        return None
    except Exception as e:
        st.error(f"è¯»å–æ–‡ä»¶æ—¶å‡ºé”™ï¼š{e}")
        return None
    
    # æå–ç‹¬ç‰¹æ´»åŠ¨åç§°
    unique_campaigns = [name for name in df_survey['å¹¿å‘Šæ´»åŠ¨åç§°'].dropna() if str(name).strip()]
    st.write(f"ç‹¬ç‰¹æ´»åŠ¨åç§°æ•°é‡: {len(unique_campaigns)}: {unique_campaigns}")
    
    # åˆ›å»ºæ´»åŠ¨åˆ° CPC/SKU/å¹¿å‘Šç»„é»˜è®¤ç«ä»·/é¢„ç®— çš„æ˜ å°„
    non_empty_campaigns = df_survey[
        df_survey['å¹¿å‘Šæ´»åŠ¨åç§°'].notna() & 
        (df_survey['å¹¿å‘Šæ´»åŠ¨åç§°'] != '')
    ]
    required_cols = ['CPC', 'SKU', 'å¹¿å‘Šç»„é»˜è®¤ç«ä»·', 'é¢„ç®—']
    if all(col in non_empty_campaigns.columns for col in required_cols):
        campaign_to_values = non_empty_campaigns.drop_duplicates(
            subset='å¹¿å‘Šæ´»åŠ¨åç§°', keep='first'
        ).set_index('å¹¿å‘Šæ´»åŠ¨åç§°')[required_cols].to_dict('index')
    else:
        campaign_to_values = {}
        st.warning(f"è­¦å‘Šï¼šç¼ºå°‘åˆ— {set(required_cols) - set(non_empty_campaigns.columns)}ï¼Œå°†ä½¿ç”¨é»˜è®¤å€¼")
    
    st.write(f"ç”Ÿæˆçš„å­—å…¸ï¼ˆæœ‰ {len(campaign_to_values)} ä¸ªæ´»åŠ¨ï¼‰: {campaign_to_values}")
    
    # å…³é”®è¯åˆ—ï¼šç¬¬ H åˆ—ï¼ˆç´¢å¼• 7ï¼‰åˆ°ç¬¬ Q åˆ—ï¼ˆç´¢å¼• 16ï¼‰
    keyword_columns = df_survey.columns[7:17]
    st.write(f"å…³é”®è¯åˆ—: {list(keyword_columns)}")
    
    # æ£€æŸ¥å…³é”®è¯é‡å¤
    duplicates_found = False
    st.write("### æ£€æŸ¥å…³é”®è¯é‡å¤")
    for col in keyword_columns:
        col_index = list(df_survey.columns).index(col) + 1
        col_letter = chr(64 + col_index) if col_index <= 26 else f"{chr(64 + (col_index-1)//26)}{chr(64 + (col_index-1)%26 + 1)}"
        kw_list = [kw for kw in df_survey[col].dropna() if str(kw).strip()]
        
        if len(kw_list) > len(set(kw_list)):
            duplicates_mask = df_survey[col].duplicated(keep=False)
            duplicates_df = df_survey[duplicates_mask][[col]].dropna()
            st.warning(f"è­¦å‘Šï¼š{col_letter} åˆ— ({col}) å­˜åœ¨é‡å¤å…³é”®è¯")
            for _, row in duplicates_df.iterrows():
                kw = str(row[col]).strip()
                count = (df_survey[col] == kw).sum()
                if count > 1:
                    st.write(f"  é‡å¤è¯: '{kw}' (å‡ºç° {count} æ¬¡)")
            duplicates_found = True
    
    if duplicates_found:
        st.error("æç¤ºï¼šç”±äºæ£€æµ‹åˆ°å…³é”®è¯é‡å¤ï¼Œç”Ÿæˆå·²ç»ˆæ­¢ã€‚è¯·æ¸…ç†é‡å¤å…³é”®è¯åé‡è¯•ã€‚")
        return None
    
    st.write("å…³é”®è¯æ— é‡å¤ï¼Œç»§ç»­ç”Ÿæˆ...")
    
    # åˆ—å®šä¹‰
    columns = [
        'äº§å“', 'å®ä½“å±‚çº§', 'æ“ä½œ', 'å¹¿å‘Šæ´»åŠ¨ç¼–å·', 'å¹¿å‘Šç»„ç¼–å·', 'å¹¿å‘Šç»„åˆç¼–å·', 'å¹¿å‘Šç¼–å·', 'å…³é”®è¯ç¼–å·', 'å•†å“æŠ•æ”¾ ID',
        'å¹¿å‘Šæ´»åŠ¨åç§°', 'å¹¿å‘Šç»„åç§°', 'å¼€å§‹æ—¥æœŸ', 'ç»“æŸæ—¥æœŸ', 'æŠ•æ”¾ç±»å‹', 'çŠ¶æ€', 'æ¯æ—¥é¢„ç®—', 'SKU', 'å¹¿å‘Šç»„é»˜è®¤ç«ä»·',
        'ç«ä»·', 'å…³é”®è¯æ–‡æœ¬', 'åŒ¹é…ç±»å‹', 'ç«ä»·æ–¹æ¡ˆ', 'å¹¿å‘Šä½', 'ç™¾åˆ†æ¯”', 'æ‹“å±•å•†å“æŠ•æ”¾ç¼–å·'
    ]
    
    # é»˜è®¤å€¼
    product = 'å•†å“æ¨å¹¿'
    operation = 'Create'
    status = 'å·²å¯ç”¨'
    targeting_type = 'æ‰‹åŠ¨'
    bidding_strategy = 'åŠ¨æ€ç«ä»· - ä»…é™ä½'
    default_daily_budget = 12
    default_group_bid = 0.6
    
    # ç”Ÿæˆæ•°æ®è¡Œ
    rows = []
    
    # æå–å…³é”®è¯ç±»åˆ«ï¼ˆJP å’Œ K EU é€šç”¨é€»è¾‘ï¼‰
    def extract_keyword_categories(df_survey):
        categories = set()
        for col in df_survey.columns:
            col_lower = str(col).lower()
            if any(x in col_lower for x in ['ç²¾å‡†è¯', 'å¹¿æ³›è¯', 'ç²¾å‡†', 'å¹¿æ³›']):
                for suffix in ['ç²¾å‡†è¯', 'å¹¿æ³›è¯', 'ç²¾å‡†', 'å¹¿æ³›']:
                    if col_lower.endswith(suffix):
                        prefix = col_lower[:-len(suffix)].strip()
                        parts = re.split(r'[/\-_\s\.]', prefix)
                        for part in parts:
                            if part and len(part) > 1:
                                categories.add(part)
                        break
            elif 'asin' in col_lower and 'å¦å®š' not in col_lower:
                prefix = col_lower.replace('asin', '').strip()
                parts = re.split(r'[/\-_\s\.]', prefix)
                for part in parts:
                    if part and len(part) > 1:
                        categories.add(part)
        categories.update(['suzhu', 'host', 'å®¿ä¸»', 'case', 'åŒ…', 'tape'])
        categories.discard('')
        return categories
    
    keyword_categories = extract_keyword_categories(df_survey)
    st.write(f"è¯†åˆ«åˆ°çš„å…³é”®è¯ç±»åˆ«: {keyword_categories}")
    
    # JP ç‰¹å®šé€»è¾‘ï¼šå¦å®šå…³é”®è¯
    def get_jp_neg_keywords(df_survey):
        neg_exact = [kw for kw in df_survey.get('å¦å®šç²¾å‡†', pd.Series()).dropna() if str(kw).strip()]
        neg_phrase = [kw for kw in df_survey.get('å¦å®šè¯ç»„', pd.Series()).dropna() if str(kw).strip()]
        suzhu_extra_neg_exact = [kw for kw in df_survey.get('å®¿ä¸»é¢å¤–å¦ç²¾å‡†', pd.Series()).dropna() if str(kw).strip()]
        suzhu_extra_neg_phrase = [kw for kw in df_survey.get('å®¿ä¸»é¢å¤–å¦è¯ç»„', pd.Series()).dropna() if str(kw).strip()]
        neg_asin = [kw for kw in df_survey.get('å¦å®šASIN', pd.Series()).dropna() if str(kw).strip()]
        return neg_exact, neg_phrase, suzhu_extra_neg_exact, suzhu_extra_neg_phrase, neg_asin
    
    # K EU ç‰¹å®šé€»è¾‘ï¼šå¦å®šå…³é”®è¯
    def get_k_eu_neg_keywords(df_survey, campaign_name, matched_category, is_broad, is_exact):
        neg_exact = []
        neg_phrase = []
        if is_broad:
            s_col = df_survey.iloc[:, 18]  # Såˆ—
            t_col = df_survey.iloc[:, 19]  # Tåˆ—
            neg_exact = [kw for kw in s_col.dropna() if str(kw).strip()]
            neg_phrase = [kw for kw in t_col.dropna() if str(kw).strip()]
        elif is_exact and matched_category:
            if matched_category in ['suzhu', 'host', 'å®¿ä¸»']:
                u_col = df_survey.iloc[:, 20]  # Uåˆ—
                v_col = df_survey.iloc[:, 21]  # Våˆ—
                neg_exact = [kw for kw in u_col.dropna() if str(kw).strip()]
                neg_phrase = [kw for kw in v_col.dropna() if str(kw).strip()]
            elif matched_category == 'case':
                w_col = df_survey.iloc[:, 22]  # Wåˆ—
                x_col = df_survey.iloc[:, 23]  # Xåˆ—
                neg_exact = [kw for kw in w_col.dropna() if str(kw).strip()]
                neg_phrase = [kw for kw in x_col.dropna() if str(kw).strip()]
        neg_exact = list(dict.fromkeys(neg_exact))
        neg_phrase = list(dict.fromkeys(neg_phrase))
        neg_asin = [kw for kw in df_survey.get('å¦å®šASIN', pd.Series()).dropna() if str(kw).strip()]
        st.write(f"å¦å®šå…³é”®è¯ï¼šç²¾å‡† {len(neg_exact)} ä¸ªï¼Œè¯ç»„ {len(neg_phrase)} ä¸ªï¼Œå¦å®šASIN {len(neg_asin)} ä¸ª")
        return neg_exact, neg_phrase, neg_asin
    
    # B US ç‰¹å®šé€»è¾‘ï¼šå¦å®šå…³é”®è¯å’Œå…³é”®è¯ç±»åˆ«æ˜ å°„
    def get_b_us_neg_keywords(df_survey):
        neg_exact = list(dict.fromkeys([kw for kw in df_survey.get('å¦å®šç²¾å‡†', pd.Series()).dropna() if str(kw).strip()]))
        neg_phrase = list(dict.fromkeys([kw for kw in df_survey.get('å¦å®šè¯ç»„', pd.Series()).dropna() if str(kw).strip()]))
        suzhu_extra_neg_exact = list(dict.fromkeys([kw for kw in df_survey.get('å®¿ä¸»é¢å¤–å¦ç²¾å‡†', pd.Series()).dropna() if str(kw).strip()]))
        suzhu_extra_neg_phrase = list(dict.fromkeys([kw for kw in df_survey.get('å®¿ä¸»é¢å¤–å¦è¯ç»„', pd.Series()).dropna() if str(kw).strip()]))
        neg_asin = list(dict.fromkeys([kw for kw in df_survey.get('å¦å®šASIN', pd.Series()).dropna() if str(kw).strip()]))
        return neg_exact, neg_phrase, suzhu_extra_neg_exact, suzhu_extra_neg_phrase, neg_asin
    
    def get_b_us_keyword_categories():
        return {
            'suzhu': 'suzhu/å®¿ä¸»-ç²¾å‡†è¯',
            'å®¿ä¸»': 'suzhu/å®¿ä¸»-ç²¾å‡†è¯',
            'case': 'case/åŒ…-ç²¾å‡†è¯',
            'åŒ…': 'case/åŒ…-ç²¾å‡†è¯',
            'cards': 'cardsç²¾å‡†è¯',
            'acces': 'accesç²¾å‡†è¯',
            'acc': 'accç²¾å‡†è¯',
            None: 'ç²¾å‡†è¯'  # XX ç»„ï¼Œé»˜è®¤åˆ—
        }
    
    # C US ç‰¹å®šé€»è¾‘ï¼šå¦å®šå…³é”®è¯
    def get_c_us_neg_keywords(df_survey):
        neg_exact = list(dict.fromkeys([kw for kw in df_survey.get('å¦å®šç²¾å‡†', pd.Series()).dropna() if str(kw).strip()]))
        neg_phrase = list(dict.fromkeys([kw for kw in df_survey.get('å¦å®šè¯ç»„', pd.Series()).dropna() if str(kw).strip()]))
        suzhu_extra_neg_exact = list(dict.fromkeys([kw for kw in df_survey.get('å®¿ä¸»é¢å¤–å¦ç²¾å‡†', pd.Series()).dropna() if str(kw).strip()]))
        suzhu_extra_neg_phrase = list(dict.fromkeys([kw for kw in df_survey.get('å®¿ä¸»é¢å¤–å¦è¯ç»„', pd.Series()).dropna() if str(kw).strip()]))
        neg_asin = list(dict.fromkeys([kw for kw in df_survey.get('å¦å®šASIN', pd.Series()).dropna() if str(kw).strip()]))
        return neg_exact, neg_phrase, suzhu_extra_neg_exact, suzhu_extra_neg_phrase, neg_asin
    
    # C US ç‰¹å®šå…³é”®è¯åŒ¹é…
    def find_matching_keyword_columns_c_us(campaign_name, df_survey, keyword_columns):
        campaign_name_normalized = str(campaign_name).lower()
        matched_category = None
        keywords = []
        matched_columns = []
        
        # æå–å…³é”®è¯ç±»åˆ«
        keyword_categories = set()
        for col in keyword_columns:
            col_lower = str(col).lower()
            if '/' in col:
                parts = col_lower.split('/')
                if parts[0]:
                    keyword_categories.add(parts[0])
                if len(parts) > 1 and parts[1]:
                    chinese_part = parts[1].split('-')[0] if '-' in parts[1] else parts[1]
                    keyword_categories.add(chinese_part)
            else:
                for suffix in ['ç²¾å‡†è¯', 'å¹¿æ³›è¯', 'ç²¾å‡†', 'å¹¿æ³›']:
                    if col_lower.endswith(suffix):
                        prefix = col_lower[:-len(suffix)]
                        if prefix:
                            keyword_categories.add(prefix)
                            break
        
        keyword_categories.update(['suzhu', 'å®¿ä¸»', 'case', 'åŒ…', 'tape'])
        st.write(f"è¯†åˆ«åˆ°çš„å…³é”®è¯ç±»åˆ«: {keyword_categories}")
        
        # åŒ¹é…å…³é”®è¯ç±»åˆ«
        for cat in keyword_categories:
            if cat in campaign_name_normalized:
                matched_category = cat
                break
        
        if matched_category:
            # æ ¹æ®åŒ¹é…ç±»å‹æ‰¾åˆ°å¯¹åº”çš„åˆ—
            if 'ç²¾å‡†' in campaign_name_normalized or 'exact' in campaign_name_normalized:
                # æŸ¥æ‰¾ç²¾å‡†åˆ—
                for col in keyword_columns:
                    col_lower = str(col).lower()
                    if matched_category in col_lower and any(x in col_lower for x in ['ç²¾å‡†', 'exact']):
                        matched_columns.append(col)
                        keywords.extend([kw for kw in df_survey[col].dropna() if str(kw).strip()])
                        st.write(f"  åŒ¹é…åˆ°ç²¾å‡†åˆ—: {col}")
                        break
            elif 'å¹¿æ³›' in campaign_name_normalized or 'broad' in campaign_name_normalized:
                # æŸ¥æ‰¾å¹¿æ³›åˆ—
                for col in keyword_columns:
                    col_lower = str(col).lower()
                    if matched_category in col_lower and any(x in col_lower for x in ['å¹¿æ³›', 'broad']):
                        matched_columns.append(col)
                        keywords.extend([kw for kw in df_survey[col].dropna() if str(kw).strip()])
                        st.write(f"  åŒ¹é…åˆ°å¹¿æ³›åˆ—: {col}")
                        break
        else:
            st.write("  æ— åŒ¹é…çš„å…³é”®è¯ç±»åˆ«")
        
        keywords = list(dict.fromkeys(keywords))  # å»é‡
        st.write(f"  å…³é”®è¯æ•°é‡: {len(keywords)} (ç¤ºä¾‹: {keywords[:2] if keywords else 'æ— '})")
        
        return matched_category, keywords
    
    # C US ç‰¹å®šå¦å®šå…³é”®è¯åˆå¹¶é€»è¾‘
    def get_c_us_campaign_neg_keywords(df_survey, campaign_name, matched_category, is_broad):
        campaign_name_normalized = str(campaign_name).lower()
        neg_exact = list(dict.fromkeys([kw for kw in df_survey.get('å¦å®šç²¾å‡†', pd.Series()).dropna() if str(kw).strip()]))
        neg_phrase = list(dict.fromkeys([kw for kw in df_survey.get('å¦å®šè¯ç»„', pd.Series()).dropna() if str(kw).strip()]))
        
        neg_keywords = []
        if is_broad and matched_category:
            for col in keyword_columns:
                col_lower = str(col).lower()
                if matched_category in col_lower and any(x in col_lower for x in ['ç²¾å‡†', 'exact']):
                    neg_keywords.extend([kw for kw in df_survey[col].dropna() if str(kw).strip()])
                if any(x in campaign_name_normalized for x in ['suzhu', 'å®¿ä¸»']) and any(x in col_lower for x in ['case', 'åŒ…']) and any(x in col_lower for x in ['ç²¾å‡†', 'exact']):
                    neg_keywords.extend([kw for kw in df_survey[col].dropna() if str(kw).strip()])
            neg_keywords = list(dict.fromkeys(neg_keywords))
            st.write(f"  ç²¾å‡†å¦å®šå…³é”®è¯æ•°é‡: {len(neg_keywords)} (ç¤ºä¾‹: {neg_keywords[:2] if neg_keywords else 'æ— '})")
        
        # åˆå¹¶ neg_exact å’Œ neg_keywordsï¼Œå»é‡
        combined_neg_exact = list(dict.fromkeys(neg_exact + neg_keywords))
        st.write(f"  åˆå¹¶åçš„å¦å®šç²¾å‡†å…³é”®è¯æ•°é‡: {len(combined_neg_exact)} (ç¤ºä¾‹: {combined_neg_exact[:2] if combined_neg_exact else 'æ— '})")
        
        return combined_neg_exact, neg_phrase
    
    # C US ç‰¹å®šASINåŒ¹é…
    def find_matching_asin_columns_c_us(campaign_name, df_survey, matched_category):
        campaign_name_normalized = str(campaign_name).lower()
        asin_targets = []
        if matched_category:
            potential_asin_cols = []
            for col in df_survey.columns:
                col_lower = str(col).lower()
                if matched_category in col_lower and 'asin' in col_lower:
                    potential_asin_cols.append(col)
            
            st.write(f"  æ½œåœ¨ASINåˆ—: {potential_asin_cols}")
            
            if potential_asin_cols:
                def calculate_match_score(col_name, campaign_norm):
                    col_lower = str(col_name).lower()
                    words = re.split(r'[\s/:-]+', col_lower)
                    unique_words = [w.strip() for w in words if w.strip() and w not in ['asin', 'ç²¾å‡†', 'å¹¿æ³›', 'exact', 'broad']]
                    score = sum(1 for word in unique_words if word in campaign_norm)
                    return score, unique_words
                
                scores = {}
                for col in potential_asin_cols:
                    score, words = calculate_match_score(col, campaign_name_normalized)
                    scores[col] = score
                    st.write(f"    åˆ— '{col}' ç‹¬ç‰¹è¯: {words}, åˆ†æ•°: {score}")
                
                best_col = max(scores, key=scores.get)
                best_score = scores[best_col]
                st.write(f"  é€‰æ‹©æœ€ä½³åˆ—: {best_col} (åˆ†æ•°: {best_score})")
                
                asin_targets.extend([kw for kw in df_survey[best_col].dropna() if str(kw).strip()])
            
            asin_targets = list(dict.fromkeys(asin_targets))
            st.write(f"  å•†å“å®šå‘ ASIN æ•°é‡: {len(asin_targets)} (ç¤ºä¾‹: {asin_targets[:2] if asin_targets else 'æ— '})")
        
        return asin_targets
    
    # æ£€æŸ¥å¦å®šå…³é”®è¯é‡å¤ï¼ˆC US ç‰¹å®šï¼‰
    def check_neg_duplicates_c_us(df_survey):
        neg_exact = list(dict.fromkeys([kw for kw in df_survey.get('å¦å®šç²¾å‡†', pd.Series()).dropna() if str(kw).strip()]))
        neg_phrase = list(dict.fromkeys([kw for kw in df_survey.get('å¦å®šè¯ç»„', pd.Series()).dropna() if str(kw).strip()]))
        suzhu_extra_neg_exact = list(dict.fromkeys([kw for kw in df_survey.get('å®¿ä¸»é¢å¤–å¦ç²¾å‡†', pd.Series()).dropna() if str(kw).strip()]))
        suzhu_extra_neg_phrase = list(dict.fromkeys([kw for kw in df_survey.get('å®¿ä¸»é¢å¤–å¦è¯ç»„', pd.Series()).dropna() if str(kw).strip()]))
        
        neg_duplicates_found = False
        st.write("### æ£€æŸ¥å¦å®šå…³é”®è¯é‡å¤")
        
        if len(neg_exact) > len(set(neg_exact)):
            neg_duplicates_found = True
            st.warning("è­¦å‘Šï¼š'å¦å®šç²¾å‡†' åˆ—æœ‰é‡å¤å…³é”®è¯")
            neg_exact_series = df_survey.get('å¦å®šç²¾å‡†', pd.Series()).dropna()
            duplicates_mask = neg_exact_series.duplicated(keep=False)
            duplicates_df = df_survey[duplicates_mask].loc[:, 'å¦å®šç²¾å‡†'].dropna()
            for _, row in duplicates_df.items():
                kw = str(row).strip()
                count = (neg_exact_series == kw).sum()
                if count > 1:
                    st.write(f"  é‡å¤è¯: '{kw}' (å‡ºç° {count} æ¬¡)")
        
        if len(neg_phrase) > len(set(neg_phrase)):
            neg_duplicates_found = True
            st.warning("è­¦å‘Šï¼š'å¦å®šè¯ç»„' åˆ—æœ‰é‡å¤å…³é”®è¯")
            neg_phrase_series = df_survey.get('å¦å®šè¯ç»„', pd.Series()).dropna()
            duplicates_mask = neg_phrase_series.duplicated(keep=False)
            duplicates_df = df_survey[duplicates_mask].loc[:, 'å¦å®šè¯ç»„'].dropna()
            for _, row in duplicates_df.items():
                kw = str(row).strip()
                count = (neg_phrase_series == kw).sum()
                if count > 1:
                    st.write(f"  é‡å¤è¯: '{kw}' (å‡ºç° {count} æ¬¡)")
        
        if len(suzhu_extra_neg_exact) > len(set(suzhu_extra_neg_exact)):
            neg_duplicates_found = True
            st.warning("è­¦å‘Šï¼š'å®¿ä¸»é¢å¤–å¦ç²¾å‡†' åˆ—æœ‰é‡å¤å…³é”®è¯")
            suzhu_exact_series = df_survey.get('å®¿ä¸»é¢å¤–å¦ç²¾å‡†', pd.Series()).dropna()
            duplicates_mask = suzhu_exact_series.duplicated(keep=False)
            duplicates_df = df_survey[duplicates_mask].loc[:, 'å®¿ä¸»é¢å¤–å¦ç²¾å‡†'].dropna()
            for _, row in duplicates_df.items():
                kw = str(row).strip()
                count = (suzhu_exact_series == kw).sum()
                if count > 1:
                    st.write(f"  é‡å¤è¯: '{kw}' (å‡ºç° {count} æ¬¡)")
        
        if len(suzhu_extra_neg_phrase) > len(set(suzhu_extra_neg_phrase)):
            neg_duplicates_found = True
            st.warning("è­¦å‘Šï¼š'å®¿ä¸»é¢å¤–å¦è¯ç»„' åˆ—æœ‰é‡å¤å…³é”®è¯")
            suzhu_phrase_series = df_survey.get('å®¿ä¸»é¢å¤–å¦è¯ç»„', pd.Series()).dropna()
            duplicates_mask = suzhu_phrase_series.duplicated(keep=False)
            duplicates_df = df_survey[duplicates_mask].loc[:, 'å®¿ä¸»é¢å¤–å¦è¯ç»„'].dropna()
            for _, row in duplicates_df.items():
                kw = str(row).strip()
                count = (suzhu_phrase_series == kw).sum()
                if count > 1:
                    st.write(f"  é‡å¤è¯: '{kw}' (å‡ºç° {count} æ¬¡)")
        
        if neg_duplicates_found:
            st.error("æç¤ºï¼šç”±äºæ£€æµ‹åˆ°å¦å®šå…³é”®è¯é‡å¤ï¼Œç”Ÿæˆå·²ç»ˆæ­¢ã€‚è¯·æ¸…ç†é‡å¤åé‡è¯•ã€‚")
            return True
        st.write("å¦å®šå…³é”®è¯æ— é‡å¤ï¼Œç»§ç»­ç”Ÿæˆ...")
        return False
    
    # æ ¹æ®å›½å®¶æ‰§è¡Œç‰¹å®šé€»è¾‘
    if country == 'C US':
        if check_neg_duplicates_c_us(df_survey):
            return None
    
    # å‡½æ•°ï¼šæŸ¥æ‰¾åŒ¹é…çš„ASINåˆ—ï¼ˆK EU é€»è¾‘ï¼ŒåŒ…å«é¢œè‰²åŒ¹é…ï¼‰
    def find_matching_asin_columns_k_eu(campaign_name, df_survey, keyword_categories):
        campaign_name_normalized = str(campaign_name).lower()
        if 'asin' not in campaign_name_normalized:
            st.write(f"  {campaign_name} ä¸æ˜¯å•†å“å®šå‘æ´»åŠ¨ï¼Œæ— åŒ¹é…ASINåˆ—")
            return []
        
        sorted_categories = sorted(keyword_categories, key=len)
        matched_category = None
        for category in sorted_categories:
            if category in campaign_name_normalized:
                matched_category = category
                break
        
        if not matched_category:
            color_words = ['çº¢', 'ç™½', 'é»‘', 'è“']
            for color in color_words:
                if color in campaign_name_normalized:
                    matched_category = color
                    st.write(f"  Fallback åŒ¹é…é¢œè‰²ç±»åˆ«: {matched_category}")
                    break
        
        if not matched_category:
            st.write(f"  {campaign_name} æœªåŒ¹é…åˆ°ä»»ä½•å…³é”®è¯ç±»åˆ«ï¼Œæ— åŒ¹é…ASINåˆ—")
            return []
        
        st.write(f"  åŒ¹é…çš„å…³é”®è¯ç±»åˆ«: {matched_category}")
        
        color = None
        color_words = ['çº¢', 'ç™½', 'é»‘', 'è“']
        for c in color_words:
            if c in campaign_name_normalized:
                color = c
                break
        st.write(f"  æå–çš„é¢œè‰²: {color}")
        
        words = re.findall(r'[a-zA-Z0-9\u4e00-\u9fff]+', campaign_name_normalized)
        exclude_words = {matched_category, 'asin', 'å•†å“å®šå‘', 'å®šå‘', 'ç²¾å‡†', 'å¹¿æ³›', 'exact', 'broad', 'host', 'case'} if matched_category else {'asin', 'å•†å“å®šå‘', 'å®šå‘', 'ç²¾å‡†', 'å¹¿æ³›', 'exact', 'broad', 'host', 'case'}
        candidate_words = [word for word in words if word not in exclude_words and len(word) > 1]
        st.write(f"  å€™é€‰åŒ¹é…è¯: {candidate_words}")
        
        matching_columns = []
        for col in df_survey.columns:
            col_lower = str(col).lower()
            if (matched_category in col_lower and 
                'asin' in col_lower and 
                'å¦å®š' not in col_lower and
                (not color or color in col_lower)):
                matching_columns.append(col)
        
        st.write(f"  åˆæ­¥åŒ¹é…çš„ASINåˆ—: {matching_columns}")
        
        if len(matching_columns) > 1:
            best_match = None
            max_matches = 0
            for col in matching_columns:
                col_lower = str(col).lower()
                match_count = sum(1 for word in candidate_words if word in col_lower)
                if match_count > max_matches:
                    max_matches = match_count
                    best_match = col
                elif match_count == max_matches and best_match:
                    best_match = col if len(col_lower) > len(best_match.lower()) else best_match
            if best_match:
                matching_columns = [best_match]
                st.write(f"  ç²¾ç»†åŒ¹é…åé€‰æ‹©åˆ—: {matching_columns}")
            else:
                st.write(f"  æ— æ³•è¿›ä¸€æ­¥ç­›é€‰ï¼Œä¿ç•™åˆæ­¥åŒ¹é…åˆ—: {matching_columns}")
        
        return matching_columns
    
    # B US ç‰¹å®šASINåŒ¹é…ï¼šç²¾ç¡®åˆ—ååŒ¹é…
    def find_matching_asin_columns_b_us(campaign_name, df_survey):
        asin_targets = []
        if campaign_name in df_survey.columns:
            asin_targets.extend([asin for asin in df_survey[campaign_name].dropna() if str(asin).strip()])
            st.write(f"  æ‰¾åˆ°ä¸æ´»åŠ¨åç§°å®Œå…¨åŒ¹é…çš„åˆ—: {campaign_name}")
        else:
            st.write(f"  æœªæ‰¾åˆ°ä¸æ´»åŠ¨åç§°å®Œå…¨åŒ¹é…çš„åˆ—: {campaign_name}")
        asin_targets = list(dict.fromkeys(asin_targets))
        st.write(f"  ASIN æ•°é‡: {len(asin_targets)} (ç¤ºä¾‹: {asin_targets[:2] if asin_targets else 'æ— '})")
        return asin_targets
    
    # å‡½æ•°ï¼šæŸ¥æ‰¾åŒ¹é…çš„å…³é”®è¯åˆ—ï¼ˆJP å’Œ K EU é€šç”¨ï¼‰
    def find_matching_keyword_columns(campaign_name, df_survey, keyword_categories, keyword_columns, match_type):
        campaign_name_normalized = str(campaign_name).lower()
        matched_categories = []
        for category in keyword_categories:
            if category and category in campaign_name_normalized:
                matched_categories.append(category)
        
        st.write(f"  åŒ¹é…çš„å…³é”®è¯ç±»åˆ«: {matched_categories}")
        
        if not matched_categories:
            st.write("  æ— åŒ¹é…çš„å…³é”®è¯ç±»åˆ«")
            return [], []
        
        match_type_keywords = ['ç²¾å‡†', 'exact'] if match_type == 'ç²¾å‡†' else ['å¹¿æ³›', 'broad']
        matching_columns = []
        for col in keyword_columns:
            col_lower = str(col).lower()
            has_match_type = any(keyword in col_lower for keyword in match_type_keywords)
            has_category = any(category in col_lower for category in matched_categories)
            if has_match_type and has_category:
                matching_columns.append(col)
        
        st.write(f"  åŒ¹é…çš„åˆ—: {matching_columns}")
        
        keywords = []
        for col in matching_columns:
            keywords.extend([kw for kw in df_survey[col].dropna() if str(kw).strip()])
        keywords = list(dict.fromkeys(keywords))
        st.write(f"  å…³é”®è¯æ•°é‡: {len(keywords)} (ç¤ºä¾‹: {keywords[:2] if keywords else 'æ— '})")
        
        return matching_columns, keywords
    
    # B US ç‰¹å®šå…³é”®è¯åŒ¹é…
    def find_matching_keyword_columns_b_us(campaign_name, df_survey, keyword_columns):
        campaign_name_normalized = str(campaign_name).lower()
        matched_category = None
        matched_columns = []
        
        # å®šä¹‰å…³é”®è¯ç±»åˆ«åˆ°ç²¾å‡†è¯åˆ—çš„æ˜ å°„
        keyword_categories_map = {
            'suzhu': 'suzhu/å®¿ä¸»-ç²¾å‡†è¯',
            'å®¿ä¸»': 'suzhu/å®¿ä¸»-ç²¾å‡†è¯',
            'case': 'case/åŒ…-ç²¾å‡†è¯',
            'åŒ…': 'case/åŒ…-ç²¾å‡†è¯',
            'cards': 'cardsç²¾å‡†è¯',
            'acces': 'accesç²¾å‡†è¯',
            'acc': 'accç²¾å‡†è¯',
            None: 'ç²¾å‡†è¯'  # XX ç»„ï¼Œé»˜è®¤åˆ—
        }
        
        keyword_categories_set = set(keyword_categories_map.keys()) - {None}
        st.write(f"è¯†åˆ«åˆ°çš„å…³é”®è¯ç±»åˆ«: {keyword_categories_set}")
        
        # é¦–å…ˆå°è¯•é¢„å®šä¹‰çš„æ˜ å°„
        for category in keyword_categories_set:
            if category in campaign_name_normalized:
                matched_category = category
                if 'ç²¾å‡†' in campaign_name_normalized:
                    target_col = keyword_categories_map[category]
                    if target_col in df_survey.columns:
                        matched_columns.append(target_col)
                elif 'å¹¿æ³›' in campaign_name_normalized:
                    target_col_broad = keyword_categories_map[category].replace('ç²¾å‡†', 'å¹¿æ³›')
                    if target_col_broad in df_survey.columns:
                        matched_columns.append(target_col_broad)
                break
        
        # å¦‚æœæ²¡æœ‰åŒ¹é…åˆ°é¢„å®šä¹‰ç»„åˆ«ï¼Œåˆ™åŒ¹é…åˆ°é…ä»¶ç»„
        if not matched_columns and ('ç²¾å‡†' in campaign_name_normalized or 'å¹¿æ³›' in campaign_name_normalized):
            matched_category = 'é…ä»¶'
            if 'ç²¾å‡†' in campaign_name_normalized:
                target_col = df_survey.columns[11]  # Låˆ—
                if target_col in df_survey.columns:
                    matched_columns.append(target_col)
                    st.write(f"  åŒ¹é…åˆ°é…ä»¶ç²¾å‡†ç»„ï¼Œä½¿ç”¨åˆ—: {target_col}")
            elif 'å¹¿æ³›' in campaign_name_normalized:
                target_col = df_survey.columns[12]  # Måˆ—
                if target_col in df_survey.columns:
                    matched_columns.append(target_col)
                    st.write(f"  åŒ¹é…åˆ°é…ä»¶å¹¿æ³›ç»„ï¼Œä½¿ç”¨åˆ—: {target_col}")
        
        st.write(f"  åŒ¹é…çš„å…³é”®è¯ç±»åˆ«: {matched_category}")
        
        # æå–å…³é”®è¯
        keywords = []
        if matched_columns:
            for col in matched_columns:
                if col in df_survey.columns:
                    col_keywords = [kw for kw in df_survey[col].dropna() if str(kw).strip()]
                    keywords.extend(col_keywords)
                    st.write(f"  ä»åˆ— {col} æå– {len(col_keywords)} ä¸ªå…³é”®è¯")
            
            keywords = list(dict.fromkeys(keywords))  # å»é‡
            st.write(f"  å…³é”®è¯æ•°é‡: {len(keywords)} (ç¤ºä¾‹: {keywords[:2] if keywords else 'æ— '})")
        else:
            st.write("  æ— åŒ¹é…çš„å…³é”®è¯åˆ—ï¼Œå…³é”®è¯ä¸ºç©º")
        
        return matched_category, keywords
    
    # å‡½æ•°ï¼šæŸ¥æ‰¾äº¤å‰å¦å®šå…³é”®è¯ï¼ˆJP é€»è¾‘ï¼‰
    def find_cross_neg_keywords_jp(campaign_name, df_survey, keyword_categories, keyword_columns):
        campaign_name_normalized = str(campaign_name).lower()
        cross_neg_keywords = []
        if any(x in campaign_name_normalized for x in ['suzhu', 'å®¿ä¸»']):
            for col in keyword_columns:
                col_lower = str(col).lower()
                if any(case_word in col_lower for case_word in ['case', 'åŒ…', 'tape']) and any(x in col_lower for x in ['ç²¾å‡†', 'exact']):
                    cross_neg_keywords.extend([kw for kw in df_survey[col].dropna() if str(kw).strip()])
        elif any(x in campaign_name_normalized for x in ['case', 'åŒ…', 'tape']):
            for col in keyword_columns:
                col_lower = str(col).lower()
                if any(suzhu_word in col_lower for suzhu_word in ['suzhu', 'å®¿ä¸»']) and any(x in col_lower for x in ['ç²¾å‡†', 'exact']):
                    cross_neg_keywords.extend([kw for kw in df_survey[col].dropna() if str(kw).strip()])
        cross_neg_keywords = list(dict.fromkeys(cross_neg_keywords))
        st.write(f"  äº¤å‰å¦å®šå…³é”®è¯æ•°é‡: {len(cross_neg_keywords)} (ç¤ºä¾‹: {cross_neg_keywords[:2] if cross_neg_keywords else 'æ— '})")
        return cross_neg_keywords
    
    # å‡½æ•°ï¼šæŸ¥æ‰¾å¦å®šå…³é”®è¯ï¼ˆK EU é€»è¾‘ï¼‰
    def find_neg_keywords_k_eu(campaign_name, df_survey, keyword_categories, keyword_columns):
        campaign_name_normalized = str(campaign_name).lower()
        sorted_categories = sorted(keyword_categories, key=len)
        matched_category = None
        for category in sorted_categories:
            if category in campaign_name_normalized:
                matched_category = category
                break
        if not matched_category:
            return []
        neg_keywords = []
        for col in keyword_columns:
            col_lower = str(col).lower()
            if matched_category in col_lower and any(x in col_lower for x in ['ç²¾å‡†', 'exact']):
                neg_keywords.extend([kw for kw in df_survey[col].dropna() if str(kw).strip()])
        neg_keywords = list(dict.fromkeys(neg_keywords))
        st.write(f"  ç²¾å‡†å¦å®šå…³é”®è¯æ•°é‡: {len(neg_keywords)} (ç¤ºä¾‹: {neg_keywords[:2] if neg_keywords else 'æ— '})")
        return neg_keywords
    
    # B US ç‰¹å®šå¦å®šå…³é”®è¯é€»è¾‘
    def get_b_us_campaign_neg_keywords(df_survey, campaign_name, matched_category, is_exact, is_broad, exact_keywords):
        campaign_name_normalized = str(campaign_name).lower()
        neg_exact = []
        neg_phrase = []
        
        # é€šç”¨å¦å®š
        neg_exact = list(dict.fromkeys([kw for kw in df_survey.get('å¦å®šç²¾å‡†', pd.Series()).dropna() if str(kw).strip()]))
        neg_phrase = list(dict.fromkeys([kw for kw in df_survey.get('å¦å®šè¯ç»„', pd.Series()).dropna() if str(kw).strip()]))
        
        if is_exact and any(x in campaign_name_normalized for x in ['suzhu', 'å®¿ä¸»']):
            # å®¿ä¸»ç²¾å‡†ç»„ï¼šä»…é€šç”¨å¦å®šç²¾å‡†
            pass
        elif is_exact:
            # å…¶ä»–ç²¾å‡†ç»„ï¼šé€šç”¨å¦å®šç²¾å‡† + é€šç”¨å¦å®šè¯ç»„
            pass
        elif is_broad:
            # å¹¿æ³›ç»„ï¼šé€šç”¨å¦å®šç²¾å‡† + é€šç”¨å¦å®šè¯ç»„ + å¯¹åº”ç²¾å‡†ç»„å…³é”®è¯ï¼ˆä½œä¸ºå¦å®šç²¾å‡†ï¼‰
            if matched_category in exact_keywords and matched_category != 'é…ä»¶':
                # é¢„å®šä¹‰å¹¿æ³›ç»„ï¼šæ·»åŠ å¯¹åº”ç²¾å‡†ç»„å…³é”®è¯
                exact_kws = exact_keywords.get(matched_category, [])
                neg_exact.extend(exact_kws)
                st.write(f"  ä¸ºé¢„å®šä¹‰å¹¿æ³›ç»„æ·»åŠ  {len(exact_kws)} ä¸ª {matched_category} ç²¾å‡†è¯ä½œä¸ºå¦å®šç²¾å‡†è¯")
            elif matched_category == 'é…ä»¶':
                # é…ä»¶å¹¿æ³›ç»„ï¼šæ·»åŠ é…ä»¶ç²¾å‡†ç»„å…³é”®è¯
                accessory_exact_col = df_survey.columns[11]  # Låˆ—
                if accessory_exact_col in df_survey.columns:
                    accessory_exact_kws = list(dict.fromkeys([kw for kw in df_survey[accessory_exact_col].dropna() if str(kw).strip()]))
                    neg_exact.extend(accessory_exact_kws)
                    st.write(f"  ä¸ºé…ä»¶å¹¿æ³›ç»„æ·»åŠ  {len(accessory_exact_kws)} ä¸ªé…ä»¶ç²¾å‡†è¯ä½œä¸ºå¦å®šç²¾å‡†è¯ (ä»åˆ—: {accessory_exact_col})")
            
            neg_exact = list(dict.fromkeys(neg_exact))  # å»é‡
        
        # ä¸ºå®¿ä¸»ç»„æ·»åŠ é¢å¤–å¦å®šå…³é”®è¯ï¼ˆå¦‚æœä¸æ˜¯å®¿ä¸»ç²¾å‡†ç»„ï¼‰
        if not (is_exact and any(x in campaign_name_normalized for x in ['suzhu', 'å®¿ä¸»'])):
            if any(x in campaign_name_normalized for x in ['suzhu', 'å®¿ä¸»']):
                suzhu_extra_neg_exact = list(dict.fromkeys([kw for kw in df_survey.get('å®¿ä¸»é¢å¤–å¦ç²¾å‡†', pd.Series()).dropna() if str(kw).strip()]))
                suzhu_extra_neg_phrase = list(dict.fromkeys([kw for kw in df_survey.get('å®¿ä¸»é¢å¤–å¦è¯ç»„', pd.Series()).dropna() if str(kw).strip()]))
                neg_exact.extend(suzhu_extra_neg_exact)
                neg_phrase.extend(suzhu_extra_neg_phrase)
                neg_exact = list(dict.fromkeys(neg_exact))
                neg_phrase = list(dict.fromkeys(neg_phrase))
        
        st.write(f"  å¦å®šå…³é”®è¯æ•°é‡: ç²¾å‡† {len(neg_exact)}, è¯ç»„ {len(neg_phrase)}")
        return neg_exact, neg_phrase
    
    # ç”Ÿæˆæ•°æ®è¡Œ
    rows = []
    for campaign_name in unique_campaigns:
        if campaign_name in campaign_to_values:
            cpc = campaign_to_values[campaign_name]['CPC']
            sku = campaign_to_values[campaign_name]['SKU']
            group_bid = campaign_to_values[campaign_name]['å¹¿å‘Šç»„é»˜è®¤ç«ä»·']
            budget = campaign_to_values[campaign_name]['é¢„ç®—']
        else:
            cpc = 0.5
            sku = 'SKU-1'
            group_bid = default_group_bid
            budget = default_daily_budget
        
        st.write(f"å¤„ç†æ´»åŠ¨: {campaign_name}")
        
        campaign_name_normalized = str(campaign_name).lower()
        is_exact = any(x in campaign_name_normalized for x in ['ç²¾å‡†', 'exact'])
        is_broad = any(x in campaign_name_normalized for x in ['å¹¿æ³›', 'broad'])
        is_asin = 'asin' in campaign_name_normalized
        match_type = 'ç²¾å‡†' if is_exact else 'å¹¿æ³›' if is_broad else 'ASIN' if is_asin else None
        st.write(f"  is_exact: {is_exact}, is_broad: {is_broad}, is_asin: {is_asin}, match_type: {match_type}")
        
        # æå–å…³é”®è¯
        keywords = []
        matched_category = None
        matched_columns = []
        if country == 'B US':
            matched_category, keywords = find_matching_keyword_columns_b_us(campaign_name, df_survey, keyword_columns)
        elif country == 'C US':
            matched_category, keywords = find_matching_keyword_columns_c_us(campaign_name, df_survey, keyword_columns)
        else:
            matched_columns, keywords = find_matching_keyword_columns(
                campaign_name, df_survey, keyword_categories, keyword_columns, match_type
            )
        
        # æå–å¦å®šå…³é”®è¯
        neg_exact = []
        neg_phrase = []
        neg_asin = []
        suzhu_extra_neg_exact = []
        suzhu_extra_neg_phrase = []
        if country == 'JP':
            neg_exact, neg_phrase, suzhu_extra_neg_exact, suzhu_extra_neg_phrase, neg_asin = get_jp_neg_keywords(df_survey)
        elif country == 'K EU':
            matched_category_k_eu = next((cat for cat in sorted(keyword_categories, key=len) if cat in campaign_name_normalized), None)
            neg_exact, neg_phrase, neg_asin = get_k_eu_neg_keywords(df_survey, campaign_name, matched_category_k_eu, is_broad, is_exact)
        elif country == 'B US':
            # B US ç‰¹å®šå¦å®šå…³é”®è¯
            keyword_categories_map = get_b_us_keyword_categories()
            exact_keywords = {key: list(dict.fromkeys([kw for kw in df_survey.get(col, pd.Series()).dropna() if str(kw).strip()]))
                              for key, col in keyword_categories_map.items() if col in df_survey.columns}
            neg_exact, neg_phrase = get_b_us_campaign_neg_keywords(df_survey, campaign_name, matched_category, is_exact, is_broad, exact_keywords)
            neg_asin = list(dict.fromkeys([kw for kw in df_survey.get('å¦å®šASIN', pd.Series()).dropna() if str(kw).strip()]))
        elif country == 'C US':
            combined_neg_exact, neg_phrase = get_c_us_campaign_neg_keywords(df_survey, campaign_name, matched_category, is_broad)
            neg_exact = combined_neg_exact
            neg_asin = list(dict.fromkeys([kw for kw in df_survey.get('å¦å®šASIN', pd.Series()).dropna() if str(kw).strip()]))
        
        # æå– ASIN
        asin_targets = []
        if is_asin:
            if country == 'B US':
                asin_targets = find_matching_asin_columns_b_us(campaign_name, df_survey)
            elif country == 'C US':
                asin_targets = find_matching_asin_columns_c_us(campaign_name, df_survey, matched_category)
            else:
                matching_columns = find_matching_asin_columns_k_eu(campaign_name, df_survey, keyword_categories) if country == 'K EU' else find_matching_keyword_columns(campaign_name, df_survey, keyword_categories, keyword_columns, 'ASIN')[0]
                for col in matching_columns:
                    asin_targets.extend([kw for kw in df_survey[col].dropna() if str(kw).strip()])
                asin_targets = list(dict.fromkeys(asin_targets))
                st.write(f"  å•†å“å®šå‘ ASIN æ•°é‡: {len(asin_targets)} (ç¤ºä¾‹: {asin_targets[:2] if asin_targets else 'æ— '})")
        
        # K EU ç‰¹æœ‰ï¼šç«ä»·è°ƒæ•´è¡Œ
        if country == 'K EU':
            placement_value = "å¹¿å‘Šä½ï¼šå•†å“é¡µé¢" if is_asin else "å¹¿å‘Šä½ï¼šæœç´¢ç»“æœé¦–é¡µé¦–ä½"
            rows.append([
                product, 'ç«ä»·è°ƒæ•´', operation, campaign_name, '', '', '', '', '',
                campaign_name, campaign_name, '', '', targeting_type, '', '', '', '',
                '', '', '', bidding_strategy, placement_value, '900', ''
            ])
            st.write(f"  æ·»åŠ ç«ä»·è°ƒæ•´è¡Œ: å¹¿å‘Šä½={placement_value}")
        
        # å¹¿å‘Šæ´»åŠ¨è¡Œ
        rows.append([
            product, 'å¹¿å‘Šæ´»åŠ¨', operation, campaign_name, '', '', '', '', '',
            campaign_name, '', '', '', targeting_type, status, budget, '', '',
            '', '', '', bidding_strategy, '', '', ''
        ])
        
        # å¹¿å‘Šç»„è¡Œ
        rows.append([
            product, 'å¹¿å‘Šç»„', operation, campaign_name, campaign_name, '', '', '', '',
            campaign_name, campaign_name, '', '', '', status, '', '', group_bid,
            '', '', '', '', '', '', ''
        ])
        
        # å•†å“å¹¿å‘Šè¡Œ
        rows.append([
            product, 'å•†å“å¹¿å‘Š', operation, campaign_name, campaign_name, '', '', '', '',
            campaign_name, campaign_name, '', '', '', status, '', sku, '',
            '', '', '', '', '', '', ''
        ])
        
        # å…³é”®è¯è¡Œ
        if is_exact or is_broad:
            for kw in keywords:
                rows.append([
                    product, 'å…³é”®è¯', operation, campaign_name, campaign_name, '', '', '', '',
                    campaign_name, campaign_name, '', '', '', status, '', '', '',
                    cpc, kw, match_type, '', '', '', ''
                ])
        
        # å¦å®šå…³é”®è¯è¡Œ
        if is_exact or is_broad:
            for kw in neg_exact:
                rows.append([
                    product, 'å¦å®šå…³é”®è¯', operation, campaign_name, campaign_name, '', '', '', '',
                    campaign_name, campaign_name, '', '', '', status, '', '', '', '',
                    kw, 'å¦å®šç²¾å‡†åŒ¹é…', '', '', '', ''
                ])
            for kw in neg_phrase:
                rows.append([
                    product, 'å¦å®šå…³é”®è¯', operation, campaign_name, campaign_name, '', '', '', '',
                    campaign_name, campaign_name, '', '', '', status, '', '', '', '',
                    kw, 'å¦å®šè¯ç»„', '', '', '', ''
                ])
            
            # JP ç‰¹æœ‰ï¼šäº¤å‰å¦å®šå’Œå®¿ä¸»é¢å¤–å¦å®š
            if country == 'JP':
                if any(x in campaign_name_normalized for x in ['suzhu', 'å®¿ä¸»']):
                    for kw in suzhu_extra_neg_exact:
                        rows.append([
                            product, 'å¦å®šå…³é”®è¯', operation, campaign_name, campaign_name, '', '', '', '',
                            campaign_name, campaign_name, '', '', '', status, '', '', '', '',
                            kw, 'å¦å®šç²¾å‡†åŒ¹é…', '', '', '', ''
                        ])
                    for kw in suzhu_extra_neg_phrase:
                        rows.append([
                            product, 'å¦å®šå…³é”®è¯', operation, campaign_name, campaign_name, '', '', '', '',
                            campaign_name, campaign_name, '', '', '', status, '', '', '', '',
                            kw, 'å¦å®šè¯ç»„', '', '', '', ''
                        ])
                cross_neg_keywords = find_cross_neg_keywords_jp(campaign_name, df_survey, keyword_categories, keyword_columns)
                for kw in cross_neg_keywords:
                    rows.append([
                        product, 'å¦å®šå…³é”®è¯', operation, campaign_name, campaign_name, '', '', '', '',
                        campaign_name, campaign_name, '', '', '', status, '', '', '', '',
                        kw, 'å¦å®šç²¾å‡†åŒ¹é…', '', '', '', ''
                    ])
            
            # K EU ç‰¹æœ‰ï¼šå¹¿æ³›ç»„å¦å®šç²¾å‡†å…³é”®è¯
            if country == 'K EU' and is_broad:
                neg_keywords = find_neg_keywords_k_eu(campaign_name, df_survey, keyword_categories, keyword_columns)
                for kw in neg_keywords:
                    rows.append([
                        product, 'å¦å®šå…³é”®è¯',